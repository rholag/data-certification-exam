{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV shows Popularity Predictor (39%)\n",
    "\n",
    "The goal of this challenge is to create a model that predicts the `popularity` of a movie or TV show\n",
    "\n",
    "<img src=\"image.jpg\" width=300 />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The dataset contains a list of movies and TV shows with the following characteristics:\n",
    "- `title`: title of the movie in english\n",
    "- `original_title`: original title of the movie \n",
    "- `duration_min`: duration of the movie in minutes\n",
    "- `popularity`: popularity of the movie in terms of review scores\n",
    "- `release_date`: release date\n",
    "- `description`: short summary of the movie\n",
    "- `budget`: budget spent to produce the movie in USD\n",
    "- `revenue`: movie revenue in USD \n",
    "- `original_language`: original language \n",
    "- `status`: is the movie already released or not\n",
    "- `number_of_awards_won`: number of awards won for the movie\n",
    "- `number_of_nominations`: number of nominations\n",
    "- `has_collection`: if the movie is part of a sequel or not\n",
    "- `all_genres`: genres that described the movie (can be zero, one or many!) \n",
    "- `top_countries`: countries where the movie was produced (can be zero, one or many!) \n",
    "- `number_of_top_productions`: number of top production companies that produced the film if any. \n",
    "Top production companies includes: Warner Bros, Universal Pictures, Paramount Pictures, Canal+, etc...\n",
    "- `available_in_english`: whether the movie is available in english or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Run the following cell to load the basic packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:05.325249Z",
     "start_time": "2021-06-29T17:29:04.415422Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nbresult import ChallengeResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "üìù **Load the `movie_popularity.csv` dataset from the provided this [URL](https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/tv_movies_popularity.csv)**\n",
    "- First, check and remove the rows that may be complete duplicate from one another (we never know!)\n",
    "- Then, drop the columns that have too much missing values\n",
    "- Finally, drop the few remaining rows that have missing values\n",
    "- Store the result in a `DataFrame` named `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/romain/code/rholag/data-certification-exam/machine_learning\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>description</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>original_language</th>\n",
       "      <th>status</th>\n",
       "      <th>number_of_awards_won</th>\n",
       "      <th>number_of_nominations</th>\n",
       "      <th>has_collection</th>\n",
       "      <th>all_genres</th>\n",
       "      <th>top_countries</th>\n",
       "      <th>number_of_top_productions</th>\n",
       "      <th>available_in_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>93.0</td>\n",
       "      <td>When Lou's shot in the groin, Nick and Jacob d...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>12314651.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>2004-08-06</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Now settled in Genovia, Princess Mia faces a n...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>95149435.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy, Drama, Family, Romance</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>2014-10-10</td>\n",
       "      <td>105.0</td>\n",
       "      <td>A promising young drummer enrolls at a cut-thr...</td>\n",
       "      <td>3300000</td>\n",
       "      <td>13092000.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>97</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>2012-03-09</td>\n",
       "      <td>122.0</td>\n",
       "      <td>A pregnant woman's search for her missing husb...</td>\n",
       "      <td>1200000</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>hi</td>\n",
       "      <td>Released</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Possession</td>\n",
       "      <td>The Possession</td>\n",
       "      <td>7.286477</td>\n",
       "      <td>2012-08-30</td>\n",
       "      <td>92.0</td>\n",
       "      <td>A young girl buys an antique box at a yard sal...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>85446075.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>Canada, United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>The King and I</td>\n",
       "      <td>The King and I</td>\n",
       "      <td>1.466461</td>\n",
       "      <td>1999-03-19</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Traveling to the exotic kingdom of Siam, Engli...</td>\n",
       "      <td>25000000</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Animation, Drama, Family</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>Little Black Book</td>\n",
       "      <td>Little Black Book</td>\n",
       "      <td>5.093704</td>\n",
       "      <td>2004-08-06</td>\n",
       "      <td>111.0</td>\n",
       "      <td>A woman snoops through her boyfriend's palm pi...</td>\n",
       "      <td>35000000</td>\n",
       "      <td>22034832.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861</th>\n",
       "      <td>The English Teacher</td>\n",
       "      <td>The English Teacher</td>\n",
       "      <td>9.673017</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>91.0</td>\n",
       "      <td>An English teacher's life is disrupted when a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6862</th>\n",
       "      <td>2001: A Space Odyssey</td>\n",
       "      <td>2001: A Space Odyssey</td>\n",
       "      <td>22.494622</td>\n",
       "      <td>1968-04-10</td>\n",
       "      <td>149.0</td>\n",
       "      <td>After discovering a mysterious artifact buried...</td>\n",
       "      <td>10500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Adventure, Mystery, Science Fiction</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>Event Horizon</td>\n",
       "      <td>Event Horizon</td>\n",
       "      <td>11.335072</td>\n",
       "      <td>1997-08-15</td>\n",
       "      <td>96.0</td>\n",
       "      <td>A rescue crew investigates a spaceship that di...</td>\n",
       "      <td>60000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Horror, Mystery, Science Fiction</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6864 rows √ó 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                original_title  \\\n",
       "0                       Hot Tub Time Machine 2   \n",
       "1     The Princess Diaries 2: Royal Engagement   \n",
       "2                                     Whiplash   \n",
       "3                                      Kahaani   \n",
       "4                               The Possession   \n",
       "...                                        ...   \n",
       "6859                            The King and I   \n",
       "6860                         Little Black Book   \n",
       "6861                       The English Teacher   \n",
       "6862                     2001: A Space Odyssey   \n",
       "6863                             Event Horizon   \n",
       "\n",
       "                                         title  popularity release_date  \\\n",
       "0                       Hot Tub Time Machine 2    6.575393   2015-02-20   \n",
       "1     The Princess Diaries 2: Royal Engagement    8.248895   2004-08-06   \n",
       "2                                     Whiplash   64.299990   2014-10-10   \n",
       "3                                      Kahaani    3.174936   2012-03-09   \n",
       "4                               The Possession    7.286477   2012-08-30   \n",
       "...                                        ...         ...          ...   \n",
       "6859                            The King and I    1.466461   1999-03-19   \n",
       "6860                         Little Black Book    5.093704   2004-08-06   \n",
       "6861                       The English Teacher    9.673017   2013-05-16   \n",
       "6862                     2001: A Space Odyssey   22.494622   1968-04-10   \n",
       "6863                             Event Horizon   11.335072   1997-08-15   \n",
       "\n",
       "      duration_min                                        description  \\\n",
       "0             93.0  When Lou's shot in the groin, Nick and Jacob d...   \n",
       "1            113.0  Now settled in Genovia, Princess Mia faces a n...   \n",
       "2            105.0  A promising young drummer enrolls at a cut-thr...   \n",
       "3            122.0  A pregnant woman's search for her missing husb...   \n",
       "4             92.0  A young girl buys an antique box at a yard sal...   \n",
       "...            ...                                                ...   \n",
       "6859          87.0  Traveling to the exotic kingdom of Siam, Engli...   \n",
       "6860         111.0  A woman snoops through her boyfriend's palm pi...   \n",
       "6861          91.0  An English teacher's life is disrupted when a ...   \n",
       "6862         149.0  After discovering a mysterious artifact buried...   \n",
       "6863          96.0  A rescue crew investigates a spaceship that di...   \n",
       "\n",
       "        budget     revenue original_language    status  number_of_awards_won  \\\n",
       "0     14000000  12314651.0                en  Released                     0   \n",
       "1     40000000  95149435.0                en  Released                     1   \n",
       "2      3300000  13092000.0                en  Released                    97   \n",
       "3      1200000  16000000.0                hi  Released                    23   \n",
       "4     14000000  85446075.0                en  Released                     0   \n",
       "...        ...         ...               ...       ...                   ...   \n",
       "6859  25000000  12000000.0                en  Released                     0   \n",
       "6860  35000000  22034832.0                en  Released                     0   \n",
       "6861         0         NaN                en  Released                     0   \n",
       "6862  10500000         NaN                en  Released                    16   \n",
       "6863  60000000         NaN                en  Released                     1   \n",
       "\n",
       "      number_of_nominations  has_collection  \\\n",
       "0                         2               1   \n",
       "1                         2               1   \n",
       "2                       145               0   \n",
       "3                        18               0   \n",
       "4                         6               0   \n",
       "...                     ...             ...   \n",
       "6859                      6               0   \n",
       "6860                      1               0   \n",
       "6861                      0               0   \n",
       "6862                     11               1   \n",
       "6863                      2               0   \n",
       "\n",
       "                               all_genres  \\\n",
       "0                                  Comedy   \n",
       "1          Comedy, Drama, Family, Romance   \n",
       "2                                   Drama   \n",
       "3                         Drama, Thriller   \n",
       "4                        Horror, Thriller   \n",
       "...                                   ...   \n",
       "6859             Animation, Drama, Family   \n",
       "6860               Comedy, Drama, Romance   \n",
       "6861                        Comedy, Drama   \n",
       "6862  Adventure, Mystery, Science Fiction   \n",
       "6863     Horror, Mystery, Science Fiction   \n",
       "\n",
       "                                 top_countries  number_of_top_productions  \\\n",
       "0                     United States of America                          3   \n",
       "1                     United States of America                          1   \n",
       "2                     United States of America                          0   \n",
       "3                                        India                          0   \n",
       "4             Canada, United States of America                          0   \n",
       "...                                        ...                        ...   \n",
       "6859                  United States of America                          1   \n",
       "6860                  United States of America                          0   \n",
       "6861                  United States of America                          0   \n",
       "6862  United Kingdom, United States of America                          1   \n",
       "6863  United Kingdom, United States of America                          1   \n",
       "\n",
       "      available_in_english  \n",
       "0                     True  \n",
       "1                     True  \n",
       "2                     True  \n",
       "3                     True  \n",
       "4                     True  \n",
       "...                    ...  \n",
       "6859                  True  \n",
       "6860                  True  \n",
       "6861                  True  \n",
       "6862                  True  \n",
       "6863                  True  \n",
       "\n",
       "[6864 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tv_movies_popularity.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:09.664618Z",
     "start_time": "2021-06-29T17:29:05.328223Z"
    },
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "revenue                      4086\n",
       "title                           1\n",
       "original_title                  0\n",
       "number_of_awards_won            0\n",
       "number_of_top_productions       0\n",
       "top_countries                   0\n",
       "all_genres                      0\n",
       "has_collection                  0\n",
       "number_of_nominations           0\n",
       "original_language               0\n",
       "status                          0\n",
       "budget                          0\n",
       "description                     0\n",
       "duration_min                    0\n",
       "release_date                    0\n",
       "popularity                      0\n",
       "available_in_english            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='revenue', inplace=True)\n",
    "data.title.replace(np.nan, \" \", inplace=True)\n",
    "data.drop_duplicates(keep=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>description</th>\n",
       "      <th>budget</th>\n",
       "      <th>original_language</th>\n",
       "      <th>status</th>\n",
       "      <th>number_of_awards_won</th>\n",
       "      <th>number_of_nominations</th>\n",
       "      <th>has_collection</th>\n",
       "      <th>all_genres</th>\n",
       "      <th>top_countries</th>\n",
       "      <th>number_of_top_productions</th>\n",
       "      <th>available_in_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>93.0</td>\n",
       "      <td>When Lou's shot in the groin, Nick and Jacob d...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>2004-08-06</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Now settled in Genovia, Princess Mia faces a n...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy, Drama, Family, Romance</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>2014-10-10</td>\n",
       "      <td>105.0</td>\n",
       "      <td>A promising young drummer enrolls at a cut-thr...</td>\n",
       "      <td>3300000</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>97</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>2012-03-09</td>\n",
       "      <td>122.0</td>\n",
       "      <td>A pregnant woman's search for her missing husb...</td>\n",
       "      <td>1200000</td>\n",
       "      <td>hi</td>\n",
       "      <td>Released</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Possession</td>\n",
       "      <td>The Possession</td>\n",
       "      <td>7.286477</td>\n",
       "      <td>2012-08-30</td>\n",
       "      <td>92.0</td>\n",
       "      <td>A young girl buys an antique box at a yard sal...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>Canada, United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>Original Sin</td>\n",
       "      <td>Original Sin</td>\n",
       "      <td>9.970359</td>\n",
       "      <td>2001-08-03</td>\n",
       "      <td>118.0</td>\n",
       "      <td>A woman, along with her lover, plans to con a ...</td>\n",
       "      <td>42000000</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>France, United States of America</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>Without a Paddle</td>\n",
       "      <td>Without a Paddle</td>\n",
       "      <td>6.046516</td>\n",
       "      <td>2004-08-20</td>\n",
       "      <td>95.0</td>\n",
       "      <td>After their friend dies, three men decide to f...</td>\n",
       "      <td>19000000</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Action, Adventure, Comedy, Thriller</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>The Verdict</td>\n",
       "      <td>The Verdict</td>\n",
       "      <td>9.596883</td>\n",
       "      <td>1982-12-08</td>\n",
       "      <td>129.0</td>\n",
       "      <td>A lawyer sees the chance to salvage his career...</td>\n",
       "      <td>16000000</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6462</th>\n",
       "      <td>It Follows</td>\n",
       "      <td>It Follows</td>\n",
       "      <td>20.359336</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>A young woman is followed by an unknown supern...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>en</td>\n",
       "      <td>Released</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>Vivre sa vie: film en douze tableaux</td>\n",
       "      <td>Vivre Sa Vie</td>\n",
       "      <td>11.305910</td>\n",
       "      <td>1962-09-20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Twelve episodic tales in the life of a Parisia...</td>\n",
       "      <td>64000</td>\n",
       "      <td>fr</td>\n",
       "      <td>Released</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6073 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                original_title  \\\n",
       "0                       Hot Tub Time Machine 2   \n",
       "1     The Princess Diaries 2: Royal Engagement   \n",
       "2                                     Whiplash   \n",
       "3                                      Kahaani   \n",
       "4                               The Possession   \n",
       "...                                        ...   \n",
       "6459                              Original Sin   \n",
       "6460                          Without a Paddle   \n",
       "6461                               The Verdict   \n",
       "6462                                It Follows   \n",
       "6463      Vivre sa vie: film en douze tableaux   \n",
       "\n",
       "                                         title  popularity release_date  \\\n",
       "0                       Hot Tub Time Machine 2    6.575393   2015-02-20   \n",
       "1     The Princess Diaries 2: Royal Engagement    8.248895   2004-08-06   \n",
       "2                                     Whiplash   64.299990   2014-10-10   \n",
       "3                                      Kahaani    3.174936   2012-03-09   \n",
       "4                               The Possession    7.286477   2012-08-30   \n",
       "...                                        ...         ...          ...   \n",
       "6459                              Original Sin    9.970359   2001-08-03   \n",
       "6460                          Without a Paddle    6.046516   2004-08-20   \n",
       "6461                               The Verdict    9.596883   1982-12-08   \n",
       "6462                                It Follows   20.359336   2015-02-04   \n",
       "6463                              Vivre Sa Vie   11.305910   1962-09-20   \n",
       "\n",
       "      duration_min                                        description  \\\n",
       "0             93.0  When Lou's shot in the groin, Nick and Jacob d...   \n",
       "1            113.0  Now settled in Genovia, Princess Mia faces a n...   \n",
       "2            105.0  A promising young drummer enrolls at a cut-thr...   \n",
       "3            122.0  A pregnant woman's search for her missing husb...   \n",
       "4             92.0  A young girl buys an antique box at a yard sal...   \n",
       "...            ...                                                ...   \n",
       "6459         118.0  A woman, along with her lover, plans to con a ...   \n",
       "6460          95.0  After their friend dies, three men decide to f...   \n",
       "6461         129.0  A lawyer sees the chance to salvage his career...   \n",
       "6462         100.0  A young woman is followed by an unknown supern...   \n",
       "6463          85.0  Twelve episodic tales in the life of a Parisia...   \n",
       "\n",
       "        budget original_language    status  number_of_awards_won  \\\n",
       "0     14000000                en  Released                     0   \n",
       "1     40000000                en  Released                     1   \n",
       "2      3300000                en  Released                    97   \n",
       "3      1200000                hi  Released                    23   \n",
       "4     14000000                en  Released                     0   \n",
       "...        ...               ...       ...                   ...   \n",
       "6459  42000000                en  Released                     0   \n",
       "6460  19000000                en  Released                     0   \n",
       "6461  16000000                en  Released                     3   \n",
       "6462   2000000                en  Released                    25   \n",
       "6463     64000                fr  Released                     3   \n",
       "\n",
       "      number_of_nominations  has_collection  \\\n",
       "0                         2               1   \n",
       "1                         2               1   \n",
       "2                       145               0   \n",
       "3                        18               0   \n",
       "4                         6               0   \n",
       "...                     ...             ...   \n",
       "6459                      2               0   \n",
       "6460                      0               1   \n",
       "6461                     14               0   \n",
       "6462                     43               0   \n",
       "6463                      1               0   \n",
       "\n",
       "                               all_genres                     top_countries  \\\n",
       "0                                  Comedy          United States of America   \n",
       "1          Comedy, Drama, Family, Romance          United States of America   \n",
       "2                                   Drama          United States of America   \n",
       "3                         Drama, Thriller                             India   \n",
       "4                        Horror, Thriller  Canada, United States of America   \n",
       "...                                   ...                               ...   \n",
       "6459                             Thriller  France, United States of America   \n",
       "6460  Action, Adventure, Comedy, Thriller          United States of America   \n",
       "6461                                Drama          United States of America   \n",
       "6462                     Horror, Thriller          United States of America   \n",
       "6463                                Drama                            France   \n",
       "\n",
       "      number_of_top_productions  available_in_english  \n",
       "0                             3                  True  \n",
       "1                             1                  True  \n",
       "2                             0                  True  \n",
       "3                             0                  True  \n",
       "4                             0                  True  \n",
       "...                         ...                   ...  \n",
       "6459                          1                  True  \n",
       "6460                          1                  True  \n",
       "6461                          1                  True  \n",
       "6462                          0                  True  \n",
       "6463                          0                 False  \n",
       "\n",
       "[6073 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Run the following cell to save your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:09.754301Z",
     "start_time": "2021-06-29T17:29:09.746171Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"data_cleaning\",\n",
    "    columns=data.columns,\n",
    "    cleaning=sum(data.isnull().sum()),\n",
    "    shape=data.shape)\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **We want to predict `popularity`: Start by plotting a histogram of the target to visualize it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Which sklearn's scoring [metric](https://scikit-learn.org/stable/modules/model_evaluation.html) should we use if we want it to:**\n",
    "\n",
    "- Be better when greater (i.e. metric_good_model > metric_bad_model)\n",
    "- Penalize **more** an error between 10 and 20 compared with an error between 110 and 120\n",
    "- Said otherwise, what matter should be the **relative error ratio**, more than the absolute error difference\n",
    "\n",
    "Hint: the histogram plotted above should give you some intuition about it\n",
    "\n",
    "üëâ Store its exact [sklearn scoring name](https://scikit-learn.org/stable/modules/model_evaluation.html) as `string` in the variable `scoring` below.\n",
    "\n",
    "üö® You must use this metric for the rest of the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.047468Z",
     "start_time": "2021-06-29T17:29:13.045265Z"
    },
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "scoring = 'recall'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° Hint</summary>\n",
    "It is around here!\n",
    "<img src=\"scores.jpg\" width=200 height=400 />\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Define `X` as the features Dataframe (keep all features) and `y` as the target Series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.054580Z",
     "start_time": "2021-06-29T17:29:13.049865Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X = data.drop(columns='popularity')\n",
    "y = data['popularity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Check unique values per features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6072"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.074836Z",
     "start_time": "2021-06-29T17:29:13.062527Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_title               5977\n",
       "title                        5968\n",
       "release_date                 4143\n",
       "duration_min                  149\n",
       "description                  6064\n",
       "budget                        613\n",
       "original_language              41\n",
       "status                          3\n",
       "number_of_awards_won          124\n",
       "number_of_nominations         178\n",
       "has_collection                  2\n",
       "all_genres                    717\n",
       "top_countries                 314\n",
       "number_of_top_productions       5\n",
       "available_in_english            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "X.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this baseline, let's forget about the columns below that are difficult to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.102327Z",
     "start_time": "2021-06-29T17:29:13.099066Z"
    }
   },
   "outputs": [],
   "source": [
    "text = ['description', 'original_title', 'title']\n",
    "dates = ['release_date'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simply scale the numerical features and one-hot-encode the categorical ones remaining\n",
    "\n",
    "üìù **Prepare 2 `list`s of features names as `str`**:\n",
    "- `numerical` which contains **only** numerical features\n",
    "- `categorical` which contains **only** categorical features (exept text and dates above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.107916Z",
     "start_time": "2021-06-29T17:29:13.104876Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "numerical = ['duration_min', 'budget', 'number_of_awards_won', 'number_of_awards_won', 'has_collection', 'number_of_top_productions']\n",
    "categorical = ['original_language', 'status', 'all_genres', 'top_countries', 'available_in_english']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining\n",
    "\n",
    "You are going to build a basic pipeline made of a basic preprocessing and a trees-based model of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing pipeline\n",
    "\n",
    "**üìù Create a basic preprocessing pipeline for the 2 types of features above:**\n",
    "- It should scale the `numerical` features\n",
    "- one-hot-encode the `categorical` and `boolean` features\n",
    "- drop the others\n",
    "- Store your pipeline in a `basic_preprocessing` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.497003Z",
     "start_time": "2021-06-29T17:29:13.477748Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "basic_preprocessing = ColumnTransformer([\n",
    "    ('num_encoder', StandardScaler(), numerical),\n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 {color: black;background-color: white;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 pre{padding: 0;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-toggleable {background-color: white;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-estimator:hover {background-color: #d4ebff;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-item {z-index: 1;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-parallel-item:only-child::after {width: 0;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-ccf3359e-972d-487d-bf9d-d3d2ba3b8517\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8d60c909-a3ec-4af2-a5c0-a426d9c5f495\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8d60c909-a3ec-4af2-a5c0-a426d9c5f495\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_encoder', StandardScaler(),\n",
       "                                 ['duration_min', 'budget',\n",
       "                                  'number_of_awards_won',\n",
       "                                  'number_of_awards_won', 'has_collection',\n",
       "                                  'number_of_top_productions']),\n",
       "                                ('cat_encoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['original_language', 'status', 'all_genres',\n",
       "                                  'top_countries', 'available_in_english'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a755c7bd-6aa3-49bf-9694-a0773a116e60\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a755c7bd-6aa3-49bf-9694-a0773a116e60\">num_encoder</label><div class=\"sk-toggleable__content\"><pre>['duration_min', 'budget', 'number_of_awards_won', 'number_of_awards_won', 'has_collection', 'number_of_top_productions']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f272bf25-b029-4747-ba44-750a36235466\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f272bf25-b029-4747-ba44-750a36235466\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b832e72d-d4c4-4bf5-ae19-87a081bf20b8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b832e72d-d4c4-4bf5-ae19-87a081bf20b8\">cat_encoder</label><div class=\"sk-toggleable__content\"><pre>['original_language', 'status', 'all_genres', 'top_countries', 'available_in_english']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"582a577c-bbc3-4cb1-ab50-3afcc0a26005\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"582a577c-bbc3-4cb1-ab50-3afcc0a26005\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore', sparse=False)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num_encoder', StandardScaler(),\n",
       "                                 ['duration_min', 'budget',\n",
       "                                  'number_of_awards_won',\n",
       "                                  'number_of_awards_won', 'has_collection',\n",
       "                                  'number_of_top_productions']),\n",
       "                                ('cat_encoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['original_language', 'status', 'all_genres',\n",
       "                                  'top_countries', 'available_in_english'])])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this cell to enable a nice display for your pipelines\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "basic_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Encode the features and store the result in the variable `X_basic_preprocessing`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.523938Z",
     "start_time": "2021-06-29T17:29:13.499042Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_basic_preprocessing = pd.DataFrame(basic_preprocessing.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1073</th>\n",
       "      <th>1074</th>\n",
       "      <th>1075</th>\n",
       "      <th>1076</th>\n",
       "      <th>1077</th>\n",
       "      <th>1078</th>\n",
       "      <th>1079</th>\n",
       "      <th>1080</th>\n",
       "      <th>1081</th>\n",
       "      <th>1082</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.794839</td>\n",
       "      <td>-0.301900</td>\n",
       "      <td>-0.416036</td>\n",
       "      <td>-0.416036</td>\n",
       "      <td>1.911450</td>\n",
       "      <td>3.535547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.186809</td>\n",
       "      <td>0.367169</td>\n",
       "      <td>-0.355240</td>\n",
       "      <td>-0.355240</td>\n",
       "      <td>1.911450</td>\n",
       "      <td>0.528141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.205850</td>\n",
       "      <td>-0.577248</td>\n",
       "      <td>5.481240</td>\n",
       "      <td>5.481240</td>\n",
       "      <td>-0.523163</td>\n",
       "      <td>-0.975562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.628550</td>\n",
       "      <td>-0.631288</td>\n",
       "      <td>0.982287</td>\n",
       "      <td>0.982287</td>\n",
       "      <td>-0.523163</td>\n",
       "      <td>-0.975562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.843921</td>\n",
       "      <td>-0.301900</td>\n",
       "      <td>-0.416036</td>\n",
       "      <td>-0.416036</td>\n",
       "      <td>-0.523163</td>\n",
       "      <td>-0.975562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>0.432221</td>\n",
       "      <td>0.418636</td>\n",
       "      <td>-0.416036</td>\n",
       "      <td>-0.416036</td>\n",
       "      <td>-0.523163</td>\n",
       "      <td>0.528141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.696674</td>\n",
       "      <td>-0.173233</td>\n",
       "      <td>-0.416036</td>\n",
       "      <td>-0.416036</td>\n",
       "      <td>1.911450</td>\n",
       "      <td>0.528141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>0.972127</td>\n",
       "      <td>-0.250433</td>\n",
       "      <td>-0.233646</td>\n",
       "      <td>-0.233646</td>\n",
       "      <td>-0.523163</td>\n",
       "      <td>0.528141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.451262</td>\n",
       "      <td>-0.610701</td>\n",
       "      <td>1.103880</td>\n",
       "      <td>1.103880</td>\n",
       "      <td>-0.523163</td>\n",
       "      <td>-0.975562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-1.187498</td>\n",
       "      <td>-0.660521</td>\n",
       "      <td>-0.233646</td>\n",
       "      <td>-0.233646</td>\n",
       "      <td>-0.523163</td>\n",
       "      <td>-0.975562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6073 rows √ó 1083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5     6     7     \\\n",
       "0    -0.794839 -0.301900 -0.416036 -0.416036  1.911450  3.535547   0.0   0.0   \n",
       "1     0.186809  0.367169 -0.355240 -0.355240  1.911450  0.528141   0.0   0.0   \n",
       "2    -0.205850 -0.577248  5.481240  5.481240 -0.523163 -0.975562   0.0   0.0   \n",
       "3     0.628550 -0.631288  0.982287  0.982287 -0.523163 -0.975562   0.0   0.0   \n",
       "4    -0.843921 -0.301900 -0.416036 -0.416036 -0.523163 -0.975562   0.0   0.0   \n",
       "...        ...       ...       ...       ...       ...       ...   ...   ...   \n",
       "6068  0.432221  0.418636 -0.416036 -0.416036 -0.523163  0.528141   0.0   0.0   \n",
       "6069 -0.696674 -0.173233 -0.416036 -0.416036  1.911450  0.528141   0.0   0.0   \n",
       "6070  0.972127 -0.250433 -0.233646 -0.233646 -0.523163  0.528141   0.0   0.0   \n",
       "6071 -0.451262 -0.610701  1.103880  1.103880 -0.523163 -0.975562   0.0   0.0   \n",
       "6072 -1.187498 -0.660521 -0.233646 -0.233646 -0.523163 -0.975562   0.0   0.0   \n",
       "\n",
       "      8     9     ...  1073  1074  1075  1076  1077  1078  1079  1080  1081  \\\n",
       "0      0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "1      0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "2      0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "3      0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4      0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "...    ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "6068   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "6069   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "6070   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "6071   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "6072   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n",
       "\n",
       "      1082  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  \n",
       "...    ...  \n",
       "6068   1.0  \n",
       "6069   1.0  \n",
       "6070   1.0  \n",
       "6071   1.0  \n",
       "6072   0.0  \n",
       "\n",
       "[6073 rows x 1083 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_basic_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùì How many features has been generated by the preprocessing? What do you think about this number?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling pipeline\n",
    "\n",
    "Let's add a model to our pipe. With so many features one-hot-encoded, we **need a model which can act as a feature selector**\n",
    "\n",
    "üëâ A linear model regularized with L1 penalty is a good starting point.\n",
    "\n",
    "\n",
    "**üìù Create a `basic_pipeline` which encapsulate the `basic_preprocessing` pipeline + a linear model with a L1 penalty**\n",
    "\n",
    "- store the resulting pipeline as `basic_pipeline`\n",
    "- don't fine-tune it\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "Choose your model from the list [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.614429Z",
     "start_time": "2021-06-29T17:29:13.609607Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import Lasso\n",
    "basic_pipeline = Pipeline([\n",
    "    ('basic_preprocessing', basic_preprocessing),\n",
    "    ('linear_model', Lasso())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb {color: black;background-color: white;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb pre{padding: 0;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-toggleable {background-color: white;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-estimator:hover {background-color: #d4ebff;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-item {z-index: 1;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-parallel-item:only-child::after {width: 0;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-44e14a8a-a272-4db9-98ce-bca6cda733eb div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-44e14a8a-a272-4db9-98ce-bca6cda733eb\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e5f05336-2726-4dae-99cc-11624dbaf068\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e5f05336-2726-4dae-99cc-11624dbaf068\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('basic_preprocessing',\n",
       "                 ColumnTransformer(transformers=[('num_encoder',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['duration_min', 'budget',\n",
       "                                                   'number_of_awards_won',\n",
       "                                                   'number_of_awards_won',\n",
       "                                                   'has_collection',\n",
       "                                                   'number_of_top_productions']),\n",
       "                                                 ('cat_encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['original_language',\n",
       "                                                   'status', 'all_genres',\n",
       "                                                   'top_countries',\n",
       "                                                   'available_in_english'])])),\n",
       "                ('linear_model', Lasso())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"062d6ede-bc7e-45c7-8153-b67dc6ba7f88\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"062d6ede-bc7e-45c7-8153-b67dc6ba7f88\">basic_preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_encoder', StandardScaler(),\n",
       "                                 ['duration_min', 'budget',\n",
       "                                  'number_of_awards_won',\n",
       "                                  'number_of_awards_won', 'has_collection',\n",
       "                                  'number_of_top_productions']),\n",
       "                                ('cat_encoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['original_language', 'status', 'all_genres',\n",
       "                                  'top_countries', 'available_in_english'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8e0cfc3c-d1eb-4ba1-a956-962ff80ecbcd\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8e0cfc3c-d1eb-4ba1-a956-962ff80ecbcd\">num_encoder</label><div class=\"sk-toggleable__content\"><pre>['duration_min', 'budget', 'number_of_awards_won', 'number_of_awards_won', 'has_collection', 'number_of_top_productions']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d46a3cdb-0def-454d-8c44-b9d04524e38b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d46a3cdb-0def-454d-8c44-b9d04524e38b\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"69545366-c214-4456-b829-161c8a9262d3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"69545366-c214-4456-b829-161c8a9262d3\">cat_encoder</label><div class=\"sk-toggleable__content\"><pre>['original_language', 'status', 'all_genres', 'top_countries', 'available_in_english']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5d9dce1e-a075-4b55-b939-74607fd69b90\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5d9dce1e-a075-4b55-b939-74607fd69b90\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore', sparse=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d4fb53c9-767a-4a88-8d25-04f0e92e6e25\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d4fb53c9-767a-4a88-8d25-04f0e92e6e25\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('basic_preprocessing',\n",
       "                 ColumnTransformer(transformers=[('num_encoder',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['duration_min', 'budget',\n",
       "                                                   'number_of_awards_won',\n",
       "                                                   'number_of_awards_won',\n",
       "                                                   'has_collection',\n",
       "                                                   'number_of_top_productions']),\n",
       "                                                 ('cat_encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['original_language',\n",
       "                                                   'status', 'all_genres',\n",
       "                                                   'top_countries',\n",
       "                                                   'available_in_english'])])),\n",
       "                ('linear_model', Lasso())])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validated baseline\n",
    "\n",
    "**üìù Perform a cross-validated evaluation of your baseline model using the metric you defined above. Store the results of this evaluation as an `array` of floating scores in the `basic_scores` variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.834847Z",
     "start_time": "2021-06-29T17:29:13.634994Z"
    },
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 396, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/indexes/range.py\", line 354, in get_loc\n",
      "    raise KeyError(key)\n",
      "KeyError: 'duration_min'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 596, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 505, in fit_transform\n",
      "    self._validate_remainder(X)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 332, in _validate_remainder\n",
      "    cols.extend(_get_column_indices(X, columns))\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 403, in _get_column_indices\n",
      "    raise ValueError(\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 396, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/indexes/range.py\", line 354, in get_loc\n",
      "    raise KeyError(key)\n",
      "KeyError: 'duration_min'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 596, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 505, in fit_transform\n",
      "    self._validate_remainder(X)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 332, in _validate_remainder\n",
      "    cols.extend(_get_column_indices(X, columns))\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 403, in _get_column_indices\n",
      "    raise ValueError(\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 396, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/indexes/range.py\", line 354, in get_loc\n",
      "    raise KeyError(key)\n",
      "KeyError: 'duration_min'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 596, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 505, in fit_transform\n",
      "    self._validate_remainder(X)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 332, in _validate_remainder\n",
      "    cols.extend(_get_column_indices(X, columns))\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 403, in _get_column_indices\n",
      "    raise ValueError(\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 396, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/indexes/range.py\", line 354, in get_loc\n",
      "    raise KeyError(key)\n",
      "KeyError: 'duration_min'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 596, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 505, in fit_transform\n",
      "    self._validate_remainder(X)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 332, in _validate_remainder\n",
      "    cols.extend(_get_column_indices(X, columns))\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 403, in _get_column_indices\n",
      "    raise ValueError(\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 396, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/indexes/range.py\", line 354, in get_loc\n",
      "    raise KeyError(key)\n",
      "KeyError: 'duration_min'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 596, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 505, in fit_transform\n",
      "    self._validate_remainder(X)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 332, in _validate_remainder\n",
      "    cols.extend(_get_column_indices(X, columns))\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 403, in _get_column_indices\n",
      "    raise ValueError(\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import cross_validate\n",
    "basic_scores = cross_validate(basic_pipeline , X_basic_preprocessing, cv = 5, scoring=scoring) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0193789 , 0.01711893, 0.00987196, 0.00956011, 0.00975466]),\n",
       " 'score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'test_score': array([nan, nan, nan, nan, nan])}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Save your results\n",
    "\n",
    "Run the following cell to save your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.848670Z",
     "start_time": "2021-06-29T17:29:13.844198Z"
    }
   },
   "outputs": [],
   "source": [
    "ChallengeResult(\n",
    "    'baseline',\n",
    "    metric=scoring,\n",
    "    features=[categorical,numerical],\n",
    "    preproc=basic_preprocessing,\n",
    "    preproc_shape=X_basic_preprocessing.shape,\n",
    "    pipe=basic_pipeline,\n",
    "    scores=basic_scores\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Features\n",
    "\n",
    "\n",
    "üëâ Let's try to improve performance using the feature `release_date`, and especially its `month` and `year`.\n",
    "\n",
    "‚ÑπÔ∏è If you want to skip this section, you can move directly to the next one: _Advanced categorical features_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Complete the custom transformer `TimeFeaturesExtractor` below**\n",
    "\n",
    "Running\n",
    "```python\n",
    "TimeFeaturesExtractor().fit_transform(X[['release_date']])\n",
    "``` \n",
    "should return something like\n",
    "\n",
    "|    |   month |   year |\n",
    "|---:|--------:|-------:|\n",
    "|  0 |       2 |   2015 |\n",
    "|  1 |       8 |   2004 |\n",
    "|  2 |      10 |   2014 |\n",
    "|  3 |       3 |   2012 |\n",
    "|  4 |       8 |   2012 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.859554Z",
     "start_time": "2021-06-29T17:29:13.855428Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TimeFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract the 2 time features from a date\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        X: DataFrame\n",
    "        y: Series\n",
    "        \n",
    "        Returns a DataFrame with 2 columns containing the time features as integers extracted from the release_date.\n",
    "        \"\"\"\n",
    "        pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.877264Z",
     "start_time": "2021-06-29T17:29:13.862231Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-5f4dbe19b1cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try your transformer and save your new features here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_time_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeFeaturesExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'release_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_time_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# Try your transformer and save your new features here\n",
    "X_time_features = TimeFeaturesExtractor().fit_transform(X[['release_date']])\n",
    "X_time_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 2 problems to solve\n",
    "- `month` is cyclical: 12 should be a close to 1 as to 11, right? \n",
    "- `year` is not scaled\n",
    "\n",
    "**üìù Build a final custom transformer `CyclicalEncoder` so that**\n",
    "\n",
    "Running\n",
    "```python\n",
    "CyclicalEncoder().fit_transform(X_time_features)\n",
    "``` \n",
    "should return something like this\n",
    "\n",
    "|    |    month_cos |   month_sin |      year |\n",
    "|---:|-------------:|------------:|----------:|\n",
    "|  0 |  0.5         |    0.866025 | 0.0466039 |\n",
    "|  1 | -0.5         |   -0.866025 | 0.0411502 |\n",
    "|  2 |  0.5         |   -0.866025 | 0.0461081 |\n",
    "|  3 |  6.12323e-17 |    1        | 0.0451165 |\n",
    "|  4 | -0.5         |   -0.866025 | 0.0451165 |\n",
    "\n",
    "With the cyclical encoding is done as below\n",
    "- `month_cos = 2 * math.pi / 12 * X[['month']] `\n",
    "- `month_sin = 2 * math.pi / 12 * X[['month']] `\n",
    "\n",
    "And the `year` begin min-max scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.884690Z",
     "start_time": "2021-06-29T17:29:13.879274Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import math\n",
    "\n",
    "class CyclicalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encode a cyclical feature\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Compute here what you need for the transform phase and store it as instance variable\n",
    "        \"\"\"\n",
    "        pass  # YOUR CODE HERE\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Compute and returns the final DataFrame\n",
    "        \"\"\"\n",
    "        pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:13.899004Z",
     "start_time": "2021-06-29T17:29:13.886894Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-6f591d85611a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try your transformer and save your new features here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_time_cyclical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCyclicalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_time_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_time_cyclical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "# Try your transformer and save your new features here\n",
    "X_time_cyclical = CyclicalEncoder().fit_transform(X_time_features)\n",
    "X_time_cyclical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:14.052971Z",
     "start_time": "2021-06-29T17:29:13.900696Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_time_cyclical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-904ddb7179ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check that this form a circle with 12 points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m plt.scatter(X_time_cyclical['month_cos'],\n\u001b[0m\u001b[1;32m      3\u001b[0m             X_time_cyclical['month_sin'])\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"month_cos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"month_sin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_time_cyclical' is not defined"
     ]
    }
   ],
   "source": [
    "# Check that this form a circle with 12 points\n",
    "plt.scatter(X_time_cyclical['month_cos'],\n",
    "            X_time_cyclical['month_sin'])\n",
    "plt.xlabel(\"month_cos\"); plt.ylabel(\"month_sin\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Enhance your `basic_pipeline` with a new preprocessing including both `TimeFeaturesExtractor` and `CyclicalFeatureExtractor`:**\n",
    "\n",
    "- Just use `TimeFeatureExtractor` if you haven't had time to do the `Cyclical` one\n",
    "- Store this new pipeline as `time_pipeline`\n",
    "- Keep same estimator for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:14.077345Z",
     "start_time": "2021-06-29T17:29:14.054521Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced categorical encoder to reduce the number of features\n",
    "\n",
    "‚ÑπÔ∏è Most of it has already been coded for you and it shouldn't take long. Still if you want to skip it and move to the next section: _Model Tuning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ We need to reduce the number of features to one-hot-encode, which arise from the high cardinality of `all_genres` and `top_countries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:14.191964Z",
     "start_time": "2021-06-29T17:29:14.184044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_genres       717\n",
       "top_countries    314\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['all_genres', 'top_countries']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Both share a common pattern: there can be more than 1 country and more than 1 genre per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:14.201275Z",
     "start_time": "2021-06-29T17:29:14.193459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_genres</th>\n",
       "      <th>top_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>France, United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>Action, Adventure, Comedy, Thriller</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>Drama</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6462</th>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>Drama</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               all_genres                     top_countries\n",
       "6459                             Thriller  France, United States of America\n",
       "6460  Action, Adventure, Comedy, Thriller          United States of America\n",
       "6461                                Drama          United States of America\n",
       "6462                     Horror, Thriller          United States of America\n",
       "6463                                Drama                            France"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['all_genres', 'top_countries']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Run the cell below where we have coded for you a custom transformer `CustomGenreAndCountryEncoder` which: \n",
    "- Select the 10 most frequent genres and the 5 most frequent countries\n",
    "- Encode `all_genres` into 10 One Hot Encoded features\n",
    "- Encode `top_countries` into 5 One Hot Encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:14.210953Z",
     "start_time": "2021-06-29T17:29:14.202791Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomGenreAndCountryEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encoding the all_genres and top_companies features which are multi-categorical :\n",
    "    a movie has several possible genres and countries of productions!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        compute top genres and top countries of productions from all_genres and top_countries features\n",
    "        \"\"\"\n",
    "\n",
    "        # compute top 10 genres       \n",
    "        list_of_genres = list(X['all_genres'].apply(lambda x: [i.strip() for i in x.split(\",\")] if x != [''] else []).values)\n",
    "        top_genres = [m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(10)]\n",
    "\n",
    "        # save top_genres in dedicated instance variable\n",
    "        self.top_genres = top_genres\n",
    "        \n",
    "         # compute top 5 countries       \n",
    "        list_of_countries = list(X['top_countries'].apply(lambda x: [i.strip() for i in x.split(\",\")] if x != [''] else []).values)\n",
    "        top_countries = [m[0] for m in Counter([i for j in list_of_countries for i in j]).most_common(5)]\n",
    "\n",
    "        # save top_countries in dedicated instance variable\n",
    "        self.top_countries = top_countries\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        encoding genre and country\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        for genre in self.top_genres:\n",
    "            X_new['genre_' + genre] = X_new['all_genres'].apply(lambda x: 1 if genre in x else 0)\n",
    "        X_new = X_new.drop(columns=[\"all_genres\"])\n",
    "        for country in self.top_countries:\n",
    "            X_new['country_' + country] = X_new['top_countries'].apply(lambda x: 1 if country in x else 0)\n",
    "        X_new = X_new.drop(columns=[\"top_countries\"])\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:14.289418Z",
     "start_time": "2021-06-29T17:29:14.212506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6073, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_Drama</th>\n",
       "      <th>genre_Comedy</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Action</th>\n",
       "      <th>genre_Romance</th>\n",
       "      <th>genre_Adventure</th>\n",
       "      <th>genre_Crime</th>\n",
       "      <th>genre_Science Fiction</th>\n",
       "      <th>genre_Horror</th>\n",
       "      <th>genre_Family</th>\n",
       "      <th>country_United States of America</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Canada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre_Drama  genre_Comedy  genre_Thriller  genre_Action  genre_Romance  \\\n",
       "0            0             1               0             0              0   \n",
       "1            1             1               0             0              1   \n",
       "2            1             0               0             0              0   \n",
       "3            1             0               1             0              0   \n",
       "4            0             0               1             0              0   \n",
       "\n",
       "   genre_Adventure  genre_Crime  genre_Science Fiction  genre_Horror  \\\n",
       "0                0            0                      0             0   \n",
       "1                0            0                      0             0   \n",
       "2                0            0                      0             0   \n",
       "3                0            0                      0             0   \n",
       "4                0            0                      0             1   \n",
       "\n",
       "   genre_Family  country_United States of America  country_United Kingdom  \\\n",
       "0             0                                 1                       0   \n",
       "1             1                                 1                       0   \n",
       "2             0                                 1                       0   \n",
       "3             0                                 0                       0   \n",
       "4             0                                 1                       0   \n",
       "\n",
       "   country_France  country_Germany  country_Canada  \n",
       "0               0                0               0  \n",
       "1               0                0               0  \n",
       "2               0                0               0  \n",
       "3               0                0               0  \n",
       "4               0                0               1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it out\n",
    "X_custom = CustomGenreAndCountryEncoder().fit_transform(X[['all_genres', 'top_countries']])\n",
    "print(X_custom.shape)\n",
    "X_custom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Compute your `final_pipeline` by integrating all these transformers** (or all those you have coded)\n",
    "\n",
    "- `CustomGenreAndCountryEncoder`\n",
    "- `TimeFeaturesExtractor`\n",
    "- `CyclicalFeatureExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:14.316693Z",
     "start_time": "2021-06-29T17:29:14.291225Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge\n",
    "final_pipeline = Pipeline([\n",
    "    ('CustomGenreAndCountryEncoder', CustomGenreAndCountryEncoder()),\n",
    "    ('model_ridge', Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Compute and store its cross validated scores as `final_scores` array of floats**\n",
    "\n",
    "- It does not necessarily improve the performance before we can try-out doing model tuning\n",
    "- However, with a now limited number of features, we will be able to train more complex models in next section (ensemble...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'all_genres'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-a94a7a57ce23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_basic_preprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \"\"\"\n\u001b[1;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-e36f9f8a0204>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# compute top 10 genres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlist_of_genres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_genres'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtop_genres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_genres\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'all_genres'"
     ]
    }
   ],
   "source": [
    "final_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Save your result\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:15.204479Z",
     "start_time": "2021-06-29T17:29:15.198198Z"
    }
   },
   "outputs": [],
   "source": [
    "ChallengeResult(\n",
    "    'feature_engineering',\n",
    "    X_time_features=X_time_features,\n",
    "    X_time_cyclical= X_time_cyclical,\n",
    "    time_pipeline=time_pipeline,\n",
    "    final_pipeline=final_pipeline,\n",
    "    final_scores=final_scores\n",
    ").write()\n",
    "\n",
    "# Hint: Try restarting your notebook if you obtain an error about saving a custom encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Change the estimator of your `final_pipeline` by a Random Forest and checkout your new cross-validated score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:19.391364Z",
     "start_time": "2021-06-29T17:29:15.206532Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'The Crying Game'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'Hot Tub Time Machine 2'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'Hot Tub Time Machine 2'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'Hot Tub Time Machine 2'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\", line 1899, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'Hot Tub Time Machine 2'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=50)\n",
    "\n",
    "final_pipeline = cross_validate(forest, X, y, scoring=scoring, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00508499, 0.00397944, 0.00412321, 0.0085535 , 0.00365877]),\n",
       " 'score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'test_score': array([nan, nan, nan, nan, nan])}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best hyperparameters quest\n",
    "\n",
    "\n",
    "\n",
    "**üìù Fine tune your model to try to get the best performance in the minimum amount of time!**\n",
    "\n",
    "- Store the result of your search inside the `search` variable.\n",
    "- Store your 5 cross-validated scores inside `best_scores` array of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:29:19.431573Z",
     "start_time": "2021-06-29T17:29:19.394891Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, {'fit_time': array([0.00508499, 0.00397944, 0.00412321, 0.0085535 , 0.00365877]), 'score_time': array([0., 0., 0., 0., 0.]), 'test_score': array([nan, nan, nan, nan, nan])} was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-170fca07215c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       scoring=scoring)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0m\u001b[1;32m    428\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, {'fit_time': array([0.00508499, 0.00397944, 0.00412321, 0.0085535 , 0.00365877]), 'score_time': array([0., 0., 0., 0., 0.]), 'test_score': array([nan, nan, nan, nan, nan])} was passed"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search = GridSearchCV(final_pipeline,\n",
    "                      param_grid={'basic_preprocessing__num_encoder__ strategy': ['mean']},\n",
    "                      cv=5,\n",
    "                      scoring=scoring)\n",
    "\n",
    "search.fit(X,y)\n",
    "best_score = search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Re-train your best pipeline on the whole (X,y) dataset**\n",
    "- Store the trained pipeline inside the `best_pipeline` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:30:18.200730Z",
     "start_time": "2021-06-29T17:30:14.992877Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Now you have your model tuned with the best hyperparameters, you are ready for a prediction.\n",
    "\n",
    "Here is a famous TV show released in 2017:\n",
    "\n",
    "```python\n",
    "dict(\n",
    "        original_title=str(\"La Casa de Papel\"),\n",
    "        title=str(\"Money Heist\"), \n",
    "        release_date= pd.to_datetime([\"2017-05-02\"]), \n",
    "        duration_min=float(50),\n",
    "        description=str(\"An unusual group of robbers attempt to carry out the most perfect robbery\"), \n",
    "        budget=float(3_000_000), \n",
    "        original_language =str(\"es\"), \n",
    "        status=str(\"Released\"),\n",
    "        number_of_awards_won =int(2), \n",
    "        number_of_nominations=int(5), \n",
    "        has_collection=int(1),\n",
    "        all_genres=str(\"Action, Crime, Mystery\"), \n",
    "        top_countries=str(\"Spain, France, United States of America\"), \n",
    "        number_of_top_productions=int('1'),\n",
    "        available_in_english=bool('True') \n",
    ")\n",
    "```\n",
    "\n",
    "**üìù Compute the predicted popularity of this TV show and store it into the `popularity` variable as a floating number.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:30:18.209145Z",
     "start_time": "2021-06-29T17:30:18.202809Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:30:18.293267Z",
     "start_time": "2021-06-29T17:30:18.211979Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:30:18.492068Z",
     "start_time": "2021-06-29T17:30:18.294946Z"
    }
   },
   "outputs": [],
   "source": [
    "ChallengeResult(\n",
    "    \"model_tuning\",\n",
    "    search=search,\n",
    "    best_pipeline=best_pipeline,\n",
    "    best_scores = best_scores,\n",
    "    popularity=popularity\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API \n",
    "\n",
    "Time to put a pipeline in production!\n",
    "\n",
    "üëâ Go to https://github.com/lewagon/data-certification-api and follow instructions\n",
    "\n",
    "**This final part is independent from the above notebook**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "572b4e543617d03e90ecaf525e08695da1ff29b13594f787e33b342cf572f792"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
