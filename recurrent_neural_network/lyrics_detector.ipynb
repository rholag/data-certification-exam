{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics detector Challenge\n",
    "\n",
    "The goal for this challenge is to leverage your knowledge of Deep Learning to design and train a lyrics classifier. For a given verse $X$, our model should learn to predict the artist $y$. The dataset consists of lyrics scrapped from the Genius website.\n",
    "\n",
    "### Objectives:\n",
    "- Text preprocessing\n",
    "- Text embedding\n",
    "- Train a RNN to detect the artist behind a set of lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.205260Z",
     "start_time": "2021-06-25T17:22:11.396250Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "\n",
    "Our dataset contains around 4,000 verses of lyrics from different artists: Drake, Ed Sheeran and Kanye West (the verses are given in this order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.654079Z",
     "start_time": "2021-06-25T17:22:16.207433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3975 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah\n",
       "1          Drake  I'm makin' a change today The liquor been taki...\n",
       "2          Drake  I can't just be with you and only you Yeah, I ...\n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...\n",
       "4          Drake  I'm makin' a change today The liquor been taki...\n",
       "...          ...                                                ...\n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...\n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...\n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"\n",
       "3973  Kanye West  Like they still weren't looking at me like a r...\n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...\n",
       "\n",
       "[3975 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/verses.csv\")\n",
    "data = raw_data.copy() # From now on, update `data` as you see fit and don't touch raw_data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Have a look at the verse index 18th**. \n",
    "- What do you observe?\n",
    "- Clean verses from non standard characters using [`unidecode.unidecode()`](https://pypi.org/project/Unidecode/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Unidecode\n",
      "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: Unidecode\n",
      "Successfully installed Unidecode-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/romain/.pyenv/versions/3.8.6/envs/lewagon/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.663663Z",
     "start_time": "2021-06-25T17:22:16.658103Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "      <td>[ayy, woah, ayy, ayy, yeah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "      <td>[i, can't, just, be, with, you, and, only, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "      <td>[well, summer, all, i, did, was, rest, okay, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "      <td>[dame, was, like, yo, you, got, a, deal, with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "      <td>[then, one, day, i, just, went, ahead, and, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "      <td>[i, ain't, gonna, front, it's, kinda, hot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "      <td>[like, they, still, weren't, looking, at, me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "      <td>[you, gotta, be, under, an, umbrella, you'll, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3029 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse  \\\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah   \n",
       "1          Drake  I'm makin' a change today The liquor been taki...   \n",
       "2          Drake  I can't just be with you and only you Yeah, I ...   \n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...   \n",
       "4          Drake  I'm makin' a change today The liquor been taki...   \n",
       "...          ...                                                ...   \n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...   \n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...   \n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"   \n",
       "3973  Kanye West  Like they still weren't looking at me like a r...   \n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...   \n",
       "\n",
       "                                                    seq  \n",
       "0                           [ayy, woah, ayy, ayy, yeah]  \n",
       "1     [i'm, makin', a, change, today, the, liquor, b...  \n",
       "2     [i, can't, just, be, with, you, and, only, you...  \n",
       "3     [well, summer, all, i, did, was, rest, okay, a...  \n",
       "4     [i'm, makin', a, change, today, the, liquor, b...  \n",
       "...                                                 ...  \n",
       "3970  [dame, was, like, yo, you, got, a, deal, with,...  \n",
       "3971  [then, one, day, i, just, went, ahead, and, pl...  \n",
       "3972         [i, ain't, gonna, front, it's, kinda, hot]  \n",
       "3973  [like, they, still, weren't, looking, at, me, ...  \n",
       "3974  [you, gotta, be, under, an, umbrella, you'll, ...  \n",
       "\n",
       "[3029 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in ['artist' ,'verse']:\n",
    "    data[col] = data[col].apply(unidecode)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Check if some verses are duplicated.** \n",
    "- It can be frequent in music lyrics.\n",
    "- If so, remove them to avoid data leaks between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.851521Z",
     "start_time": "2021-06-25T17:22:16.842793Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3029,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data['verse'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset =\"verse\", keep = 'first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.861084Z",
     "start_time": "2021-06-25T17:22:16.854026Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_loading',\n",
    "    shape=data.shape,\n",
    "    verses=data.verse[:50]\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis (given to you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ **We check the number of unique artist and the number of verses per artist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.182432Z",
     "start_time": "2021-06-25T17:22:19.175936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drake         1391\n",
       "Ed Sheeran     861\n",
       "Kanye West     777\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.artist.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ **For each artist, let's have a look at the top-10 most used words to see if they look similar?**\n",
    "\n",
    "We'll use Tensorflow's [`Tokenizer`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)'s index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.191343Z",
     "start_time": "2021-06-25T17:22:19.184174Z"
    }
   },
   "outputs": [],
   "source": [
    "drake = data[data.artist =='Drake'].verse\n",
    "ed = data[data.artist =='Ed Sheeran'].verse\n",
    "kanye = data[data.artist =='Kanye West'].verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.438880Z",
     "start_time": "2021-06-25T17:22:19.193277Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_drake = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_ed = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_kanye = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer_drake.fit_on_texts(drake)\n",
    "tokenizer_ed.fit_on_texts(ed)\n",
    "tokenizer_kanye.fit_on_texts(kanye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.457776Z",
     "start_time": "2021-06-25T17:22:19.441016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drake</th>\n",
       "      <th>Ed Sheeran</th>\n",
       "      <th>Kanye West</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>me</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>my</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>to</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>me</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i'm</td>\n",
       "      <td>in</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>my</td>\n",
       "      <td>i'm</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Drake Ed Sheeran Kanye West\n",
       "1      i          i          i\n",
       "2    you        you        the\n",
       "3    the        the        you\n",
       "4    and        and        and\n",
       "5     to         me         to\n",
       "6      a         my          a\n",
       "7     it         to         my\n",
       "8     me          a         it\n",
       "9    i'm         in         me\n",
       "10    my        i'm         in"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={\n",
    "    \"Drake\": pd.Series(tokenizer_drake.index_word)[:10],\n",
    "    \"Ed Sheeran\": pd.Series(tokenizer_ed.index_word)[:10],\n",
    "    \"Kanye West\": pd.Series(tokenizer_kanye.index_word)[:10],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ **Let's quantify how much vocabulary do they have in common**\n",
    "\n",
    "- An artist **vocabulary** is the **set** of all unique used words\n",
    "- We compute the `ratio` of (i) the length of vocabulary they **share**, over (ii) the length of the **total** vocabulary of the dataset\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "We'll use Python [`set.intersection()`](https://www.programiz.com/python-programming/methods/set/intersection) and [`set.union()`](https://www.programiz.com/python-programming/methods/set/union)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.465228Z",
     "start_time": "2021-06-25T17:22:19.460132Z"
    }
   },
   "outputs": [],
   "source": [
    "drake_vocabulary = set(tokenizer_drake.index_word.values())\n",
    "ed_vocabulary = set(tokenizer_ed.index_word.values())\n",
    "kanye_vocabulary = set(tokenizer_kanye.index_word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.474902Z",
     "start_time": "2021-06-25T17:22:19.467454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.26% of the artists' vocabulary is common\n"
     ]
    }
   ],
   "source": [
    "common_vocabulary = drake_vocabulary.intersection(ed_vocabulary).intersection(kanye_vocabulary)\n",
    "global_vocabulary = drake_vocabulary.union(ed_vocabulary).union(kanye_vocabulary)\n",
    "\n",
    "ratio = len(common_vocabulary)/len(global_vocabulary)\n",
    "print(f\"{ratio*100:.2f}% of the artists' vocabulary is common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Word Embedding\n",
    "We now need to think about embedding our sentences into numbers. We will be using [`gensim.models.Word2Vec`](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) to embed each word of the sentence and concatenate the embeddings of the words forming the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Transform the list of strings (verses) into a list of word sequences (a word sequence is a list of words contained in a string)**\n",
    "- Store these sequences of words in a new column `data[\"seq\"]` in your dataframe\n",
    "- You can use `tensorflow.keras.preprocessing.text.text_to_word_sequence` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec as wc\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.569442Z",
     "start_time": "2021-06-25T17:22:19.478291Z"
    },
    "scrolled": false,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "      <td>[ayy, woah, ayy, ayy, yeah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "      <td>[i, can't, just, be, with, you, and, only, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "      <td>[well, summer, all, i, did, was, rest, okay, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "      <td>[dame, was, like, yo, you, got, a, deal, with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "      <td>[then, one, day, i, just, went, ahead, and, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "      <td>[i, ain't, gonna, front, it's, kinda, hot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "      <td>[like, they, still, weren't, looking, at, me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "      <td>[you, gotta, be, under, an, umbrella, you'll, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3029 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse  \\\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah   \n",
       "1          Drake  I'm makin' a change today The liquor been taki...   \n",
       "2          Drake  I can't just be with you and only you Yeah, I ...   \n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...   \n",
       "4          Drake  I'm makin' a change today The liquor been taki...   \n",
       "...          ...                                                ...   \n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...   \n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...   \n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"   \n",
       "3973  Kanye West  Like they still weren't looking at me like a r...   \n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...   \n",
       "\n",
       "                                                    seq  \n",
       "0                           [ayy, woah, ayy, ayy, yeah]  \n",
       "1     [i'm, makin', a, change, today, the, liquor, b...  \n",
       "2     [i, can't, just, be, with, you, and, only, you...  \n",
       "3     [well, summer, all, i, did, was, rest, okay, a...  \n",
       "4     [i'm, makin', a, change, today, the, liquor, b...  \n",
       "...                                                 ...  \n",
       "3970  [dame, was, like, yo, you, got, a, deal, with,...  \n",
       "3971  [then, one, day, i, just, went, ahead, and, pl...  \n",
       "3972         [i, ain't, gonna, front, it's, kinda, hot]  \n",
       "3973  [like, they, still, weren't, looking, at, me, ...  \n",
       "3974  [you, gotta, be, under, an, umbrella, you'll, ...  \n",
       "\n",
       "[3029 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data['seq'] = data['verse'].apply(text_to_word_sequence)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Let's check if we can cap the length of each sequences without losing too much information**\n",
    "- Plot the distribution of sequences lengths using the [`seaborn.kdeplot`](https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn-displot) function\n",
    "- Does it seem reasonable to limit ourself to 300 words per verse later on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.783874Z",
     "start_time": "2021-06-25T17:22:19.572393Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "sns.kdeplot(data=data, x='seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Keep only the first `300` words of each sequences to reduce the useless long tail of long verses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(data['seq'],\n",
    "                                   test_size = 0.3, \n",
    "                                   random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=X_train[:300], vector_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Train a `gensim.models.Word2Vec` model on your dataset** \n",
    "- You want to embed each word into vectors of dimension `100`\n",
    "- No words should be excluded\n",
    "- Give Word2Vec at least 50 epochs to be sure it converges\n",
    "- Store these lists of vectors in a new column `data[\"embed\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 100\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=300, # vocab_size\n",
    "                               input_length=50, # sentences_lengths\n",
    "                               output_dim=20, # embedding_size\n",
    "                               mask_zero=True))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:27.636650Z",
     "start_time": "2021-06-25T17:22:27.634359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check \n",
    "assert len(data['embed']) == len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Create your numpy array `X` of shape (number_of_verses, 300, 100)**\n",
    "\n",
    "- 300 words per verse (pad verses shorter than 300 with zeros at the end) \n",
    "- each words being a vector of size 100\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lewagon/data-images/master/DL/padding.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.272086Z",
     "start_time": "2021-06-25T17:22:27.638449Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Create the numpy array `y` of shape `(n_verses, 3)` that contains the one-hot-encoded list of labels, for the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.394015Z",
     "start_time": "2021-06-25T17:22:28.274638Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ We train/test split the dataset below for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.558686Z",
     "start_time": "2021-06-25T17:22:28.400774Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.803743Z",
     "start_time": "2021-06-25T17:22:29.563431Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_preprocessing',\n",
    "    n_zeros = np.sum(X == 0),\n",
    "    X_shape = X.shape,\n",
    "    y_shape = y.shape,\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Run this code below if you haven't managed to build your own (X,Y) training sets. This will load them as solution\n",
    "\n",
    "```python\n",
    "! wget \\\n",
    "'https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_lyrics_solution.pickle'\n",
    "\n",
    "import pickle\n",
    "with open(\"data_lyrics_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, y_train, X_test, y_test) = pickle.load(file)\n",
    "    \n",
    "! rm data_lyrics_solution.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-29 17:44:23--  https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_lyrics_solution.pickle\n",
      "Resolving wagon-public-datasets.s3.amazonaws.com (wagon-public-datasets.s3.amazonaws.com)... 52.218.112.162\n",
      "Connecting to wagon-public-datasets.s3.amazonaws.com (wagon-public-datasets.s3.amazonaws.com)|52.218.112.162|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 727513032 (694M) [application/octet-stream]\n",
      "Saving to: ‚Äòdata_lyrics_solution.pickle‚Äô\n",
      "\n",
      "data_lyrics_solutio 100%[===================>] 693.81M  2.12MB/s    in 5m 28s  \n",
      "\n",
      "2021-06-29 17:49:51 (2.12 MB/s) - ‚Äòdata_lyrics_solution.pickle‚Äô saved [727513032/727513032]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget \\\n",
    "'https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_lyrics_solution.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data_lyrics_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, y_train, X_test, y_test) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm data_lyrics_solution.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **First, store your baseline accuracy to beat as `score_baseline`**\n",
    "- Consider predicting always the most frequent artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:33.555223Z",
     "start_time": "2021-06-25T17:22:33.547120Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/base.py:426: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  warnings.warn(\"The default value of multioutput (not exposed in \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0004945275665734301"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.dummy import DummyRegressor\n",
    "baseline_model = DummyRegressor(strategy=\"mean\")\n",
    "baseline_model.fit(X_train, y_train) \n",
    "score_baseline = baseline_model.score(X_test, y_test)\n",
    "score_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Create a RNN architecture to predict the artists `y`  given verses `X`** :\n",
    "\n",
    "- Keep it simple: use only one LSTM layer and one *hidden* dense layer between the input and output layers\n",
    "- Don't forget to take care of fake \"zeros\" added during preprocessing\n",
    "- Store it into the `model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:27:09.448283Z",
     "start_time": "2021-06-25T17:27:08.796094Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, None, 100)         201       \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 30,922\n",
      "Trainable params: 30,721\n",
      "Non-trainable params: 201\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "normal = Normalization()\n",
    "normal.adapt(X_train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(normal)\n",
    "model.add(layers.LSTM(units=50, activation='tanh', input_shape=(4,3)))\n",
    "\n",
    "model.add(layers.Dense(10, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"relu\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Train your `model` on the `(X_train, y_train)` training set**\n",
    "- Use an appropriate loss\n",
    "- Adapt the learning rate of your optimizer if convergence is too slow/fast\n",
    "- Make sure your model does not overfit with appropriate control techniques\n",
    "\n",
    "üí° You will not be judged by the computing power of your computer, you can reach decent performance in less than 3 minutes of training without GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.790957Z",
     "start_time": "2021-06-25T17:27:09.537171Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "model.compile(loss='mse', \n",
    "              optimizer='rmsprop',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Plot the training and validation losses through training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.814449Z",
     "start_time": "2021-06-25T17:28:13.793297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "122/122 [==============================] - 28s 213ms/step - loss: 0.3329 - mae: 0.3338 - val_loss: 0.3327 - val_mae: 0.3352\n",
      "Epoch 2/20\n",
      "122/122 [==============================] - 24s 201ms/step - loss: 0.3336 - mae: 0.3350 - val_loss: 0.3330 - val_mae: 0.3340\n",
      "Epoch 3/20\n",
      "122/122 [==============================] - 25s 204ms/step - loss: 0.3330 - mae: 0.3346 - val_loss: 0.3328 - val_mae: 0.3339\n",
      "Epoch 4/20\n",
      "122/122 [==============================] - 25s 205ms/step - loss: 0.3329 - mae: 0.3337 - val_loss: 0.3328 - val_mae: 0.3342\n",
      "Epoch 5/20\n",
      "122/122 [==============================] - 25s 202ms/step - loss: 0.3328 - mae: 0.3346 - val_loss: 0.3324 - val_mae: 0.3345\n",
      "Epoch 6/20\n",
      "122/122 [==============================] - 24s 200ms/step - loss: 0.3323 - mae: 0.3348 - val_loss: 0.3318 - val_mae: 0.3349\n",
      "Epoch 7/20\n",
      "122/122 [==============================] - 24s 200ms/step - loss: 0.3314 - mae: 0.3355 - val_loss: 0.3319 - val_mae: 0.3346\n",
      "Epoch 8/20\n",
      "122/122 [==============================] - 24s 199ms/step - loss: 0.3315 - mae: 0.3355 - val_loss: 0.3314 - val_mae: 0.3353\n",
      "Epoch 9/20\n",
      "122/122 [==============================] - 24s 201ms/step - loss: 0.3309 - mae: 0.3362 - val_loss: 0.3313 - val_mae: 0.3353\n",
      "Epoch 10/20\n",
      "122/122 [==============================] - 25s 201ms/step - loss: 0.3309 - mae: 0.3358 - val_loss: 0.3313 - val_mae: 0.3351\n",
      "Epoch 11/20\n",
      "122/122 [==============================] - 25s 202ms/step - loss: 0.3311 - mae: 0.3358 - val_loss: 0.3311 - val_mae: 0.3352\n",
      "Epoch 12/20\n",
      "122/122 [==============================] - 25s 206ms/step - loss: 0.3025 - mae: 0.3644 - val_loss: 0.2250 - val_mae: 0.4489\n",
      "Epoch 13/20\n",
      "122/122 [==============================] - 24s 201ms/step - loss: 0.2233 - mae: 0.4439 - val_loss: 0.2236 - val_mae: 0.4386\n",
      "Epoch 14/20\n",
      "122/122 [==============================] - 24s 199ms/step - loss: 0.2228 - mae: 0.4441 - val_loss: 0.2231 - val_mae: 0.4477\n",
      "Epoch 15/20\n",
      "122/122 [==============================] - 24s 199ms/step - loss: 0.2231 - mae: 0.4437 - val_loss: 0.2227 - val_mae: 0.4466\n",
      "Epoch 16/20\n",
      "122/122 [==============================] - 24s 199ms/step - loss: 0.2225 - mae: 0.4444 - val_loss: 0.2227 - val_mae: 0.4454\n",
      "Epoch 17/20\n",
      "122/122 [==============================] - 24s 200ms/step - loss: 0.2224 - mae: 0.4444 - val_loss: 0.2226 - val_mae: 0.4428\n",
      "Epoch 18/20\n",
      " 76/122 [=================>............] - ETA: 8s - loss: 0.2229 - mae: 0.4437"
     ]
    }
   ],
   "source": [
    "# Plot below your train/val loss history\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "es = EarlyStopping(patience=5, restore_best_weights = True) \n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=20,  # Use early stop in practice\n",
    "          batch_size=16, \n",
    "          verbose=1,\n",
    "          callbacks=[es],\n",
    "          validation_split=0.2)\n",
    "\n",
    "# Run also this code to save figure as jpg in path below (it's your job to ensure it works)\n",
    "fig = plt.gcf()\n",
    "plt.savefig(\"tests/history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Save your accuracy on test set as `score_test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:29:15.350717Z",
     "start_time": "2021-06-25T17:29:14.925473Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 40ms/step - loss: 0.2231 - mae: 0.4414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22314657270908356, 0.4414389431476593]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "score_test = model.evaluate(X_test, y_test)\n",
    "score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Send your results below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:25:11.216908Z",
     "start_time": "2021-06-25T17:25:11.208773Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"network\",\n",
    "    loss = model.loss,\n",
    "    input_shape = list(model.input.shape),\n",
    "    layer_names = [layer.name for layer in model.layers],\n",
    "    final_activation = model.layers[-1].activation.__wrapped__._keras_api_names[0],\n",
    "    score_baseline = score_baseline,\n",
    "    score_test = score_test,\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "330.513px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
